# YOLO è½‰ ONNX å®Œæ•´æ•™å­¸æŒ‡å—

æœ¬æŒ‡å—å°‡è©³ç´°ä»‹ç´¹å¦‚ä½•å°‡è¨“ç·´å¥½çš„ YOLOv8 æ¨¡å‹è½‰æ›ç‚º ONNX æ ¼å¼ï¼Œä»¥åŠä¸åŒ ONNX Runtime ç‰ˆæœ¬çš„å°æ‡‰è¨­å®šã€‚

## ç›®éŒ„
1. [ä»€éº¼æ˜¯ ONNXï¼Ÿ](#ä»€éº¼æ˜¯-ONNX)
2. [ç‚ºä»€éº¼è¦è½‰æ›ç‚º ONNXï¼Ÿ](#ç‚ºä»€éº¼è¦è½‰æ›ç‚º-ONNX)
3. [ç‰ˆæœ¬å°æ‡‰è¡¨](#ç‰ˆæœ¬å°æ‡‰è¡¨)
4. [ç’°å¢ƒæº–å‚™](#ç’°å¢ƒæº–å‚™)
5. [è½‰æ›æ–¹æ³•è©³è§£](#è½‰æ›æ–¹æ³•è©³è§£)
6. [åƒæ•¸è©³ç´°èªªæ˜](#åƒæ•¸è©³ç´°èªªæ˜)
7. [å¸¸è¦‹å•é¡Œèˆ‡è§£æ±ºæ–¹æ¡ˆ](#å¸¸è¦‹å•é¡Œèˆ‡è§£æ±ºæ–¹æ¡ˆ)
8. [é©—è­‰èˆ‡æ¸¬è©¦](#é©—è­‰èˆ‡æ¸¬è©¦)

---

## ä»€éº¼æ˜¯ ONNXï¼Ÿ

**ONNX (Open Neural Network eXchange)** æ˜¯ä¸€å€‹é–‹æ”¾çš„ç¥ç¶“ç¶²è·¯äº¤æ›æ ¼å¼ï¼Œå®ƒå…è¨±ä¸åŒæ·±åº¦å­¸ç¿’æ¡†æ¶ä¹‹é–“é€²è¡Œæ¨¡å‹è½‰æ›å’Œéƒ¨ç½²ã€‚

### ğŸ¯ ONNX çš„å„ªå‹¢
- **è·¨å¹³å°éƒ¨ç½²**ï¼šå¯åœ¨ä¸åŒä½œæ¥­ç³»çµ±é‹è¡Œ
- **è·¨æ¡†æ¶æ”¯æ´**ï¼šæ”¯æ´ PyTorchã€TensorFlowã€scikit-learn ç­‰
- **é«˜æ•ˆæ¨ç†**ï¼šå„ªåŒ–æ¨ç†é€Ÿåº¦ï¼Œé™ä½å»¶é²
- **ç¡¬é«”æœ€ä½³åŒ–**ï¼šæ”¯æ´ CPUã€GPUã€é‚Šç·£è¨­å‚™ç­‰

---

## ç‚ºä»€éº¼è¦è½‰æ›ç‚º ONNXï¼Ÿ

### ğŸ“± éƒ¨ç½²éœ€æ±‚
1. **ç”Ÿç”¢ç’°å¢ƒéƒ¨ç½²**ï¼šä¼ºæœå™¨ç«¯é«˜æ•ˆæ¨ç†
2. **é‚Šç·£è¨­å‚™é‹è¡Œ**ï¼šæ‰‹æ©Ÿã€åµŒå…¥å¼ç³»çµ±
3. **è·¨èªè¨€æ”¯æ´**ï¼šC++ã€Javaã€C# ç­‰èªè¨€èª¿ç”¨
4. **é›²ç«¯æœå‹™æ•´åˆ**ï¼šAzure MLã€AWS SageMaker ç­‰

### âš¡ æ•ˆèƒ½å„ªå‹¢
- **æ¨ç†é€Ÿåº¦æå‡**ï¼šç›¸æ¯”åŸå§‹ PyTorch æ¨¡å‹å¿« 2-5 å€
- **è¨˜æ†¶é«”ä½¿ç”¨é™ä½**ï¼šæ¨¡å‹å¤§å°é€šå¸¸æ¸›å°‘ 20-50%
- **æ‰¹æ¬¡è™•ç†å„ªåŒ–**ï¼šæ”¯æ´å‹•æ…‹æ‰¹æ¬¡å¤§å°

---

## ç‰ˆæœ¬å°æ‡‰è¡¨

### ğŸ”§ ONNX Runtime èˆ‡ Opset ç‰ˆæœ¬å°æ‡‰

| ONNX Runtime ç‰ˆæœ¬ | æ”¯æ´çš„æœ€é«˜ Opset | å»ºè­° Opset | ç™¼å¸ƒæ™‚é–“ | å‚™è¨» |
|-------------------|-----------------|------------|----------|------|
| **1.15.1** | **18** | **15** | 2023-06 | ğŸŒŸ æ¨è–¦ç‰ˆæœ¬ |
| **1.12.1** | **17** | **11** | 2022-08 | ç©©å®šç‰ˆæœ¬ |


### ğŸ“‹ æ¨è–¦é…ç½®

#### ğŸŒŸ æœ€æ–°ç©©å®šé…ç½® (æ¨è–¦)
```python
# é©ç”¨æ–¼ ONNX Runtime 1.15.1
opset = 15
```

#### ğŸ”’ ç›¸å®¹ç©©å®šé…ç½®
```python
# é©ç”¨æ–¼ ONNX Runtime 1.12.1
opset = 11
```

#### âš ï¸ å®‰å…¨é€šç”¨é…ç½®
```python
# é©ç”¨æ–¼å¤§å¤šæ•¸ç‰ˆæœ¬
opset = 11  # é€šç”¨ç›¸å®¹æ€§æœ€ä½³
```

---

## ç’°å¢ƒæº–å‚™

### 1. å®‰è£å¿…è¦å¥—ä»¶

```bash
# ç¢ºä¿æœ‰æœ€æ–°çš„ ultralytics
pip install ultralytics>=8.0.0

# å®‰è£ ONNX ç›¸é—œå¥—ä»¶
pip install onnx>=1.12.0
pip install onnxruntime>=1.12.1  # æˆ– onnxruntime-gpu

# å¯é¸ï¼šå®‰è£æ¨¡å‹æœ€ä½³åŒ–å·¥å…·
pip install onnx-simplifier
```

### 2. æª¢æŸ¥ç’°å¢ƒ

```python
import ultralytics
import onnx
import onnxruntime
import torch

print(f"Ultralytics: {ultralytics.__version__}")
print(f"ONNX: {onnx.__version__}")
print(f"ONNX Runtime: {onnxruntime.__version__}")
print(f"PyTorch: {torch.__version__}")
```

---

## è½‰æ›æ–¹æ³•è©³è§£

### ğŸ¯ åŸºæœ¬è½‰æ›æ–¹æ³•

```python
from ultralytics import YOLO
import shutil
import os

# ============================================
# åŸºæœ¬è¨­å®š
# ============================================

# è¼¸å…¥æª”æ¡ˆè·¯å¾‘ï¼ˆè¨“ç·´å¥½çš„ .pt æª”æ¡ˆï¼‰
loadyolo_path = r'path/to/your/best.pt'

# è¼¸å‡ºæª”æ¡ˆè·¯å¾‘ï¼ˆæƒ³è¦å„²å­˜çš„ .onnx æª”æ¡ˆä½ç½®ï¼‰
target_path = r'path/to/output/model.onnx'

print("=== YOLO è½‰ ONNX è½‰æ›é–‹å§‹ ===")

# ============================================
# æ–¹æ³•ä¸€ï¼šåŸºæœ¬è½‰æ›ï¼ˆæ¨è–¦ï¼‰
# ============================================

# è¼‰å…¥è¨“ç·´å¥½çš„æ¨¡å‹
model = YOLO(loadyolo_path)

# åŸ·è¡Œè½‰æ›
onnx_path = model.export(
    format='onnx',          # è¼¸å‡ºæ ¼å¼
    imgsz=320,             # è¼¸å…¥åœ–ç‰‡å°ºå¯¸ï¼ˆå¿…é ˆèˆ‡è¨“ç·´æ™‚ä¸€è‡´ï¼‰
    opset=17,              # ONNX opset ç‰ˆæœ¬ï¼ˆæ ¹æ“š Runtime ç‰ˆæœ¬é¸æ“‡ï¼‰
    simplify=True,         # ç°¡åŒ–æ¨¡å‹çµæ§‹
    dynamic=False,         # æ˜¯å¦æ”¯æ´å‹•æ…‹å½¢ç‹€
    half=False             # æ˜¯å¦ä½¿ç”¨åŠç²¾åº¦
)

print(f"âœ… æ¨¡å‹è½‰æ›å®Œæˆ: {onnx_path}")

# ç§»å‹•åˆ°ç›®æ¨™ä½ç½®
if target_path != onnx_path:
    shutil.move(onnx_path, target_path)
    print(f"âœ… æª”æ¡ˆç§»å‹•è‡³: {target_path}")

print("=== è½‰æ›å®Œæˆ ===")
```

### ğŸ”§ é€²éšè½‰æ›é¸é …

#### ç‰ˆæœ¬ 1.15.1 æœ€ä½³åŒ–é…ç½®
```python
# é©ç”¨æ–¼ ONNX Runtime 1.15.1
model.export(
    format='onnx',
    imgsz=320,
    opset=17,              # æœ€æ–°æ”¯æ´ç‰ˆæœ¬
    simplify=True,         # å•Ÿç”¨æ¨¡å‹ç°¡åŒ–
    dynamic=False,         # å›ºå®šè¼¸å…¥å°ºå¯¸ä»¥æå‡æ•ˆèƒ½
    half=False,            # ä½¿ç”¨ FP32 ç¢ºä¿ç²¾åº¦
    int8=False,            # ä¸ä½¿ç”¨ INT8 é‡åŒ–
    device='cpu'           # æŒ‡å®šè½‰æ›è¨­å‚™
)
```

#### ç‰ˆæœ¬ 1.12.1 ç›¸å®¹é…ç½®
```python
# é©ç”¨æ–¼ ONNX Runtime 1.12.1
model.export(
    format='onnx',
    imgsz=320,
    opset=15,              # ç›¸å®¹ç‰ˆæœ¬
    simplify=True,
    dynamic=False,
    half=False,
    device='cpu'
)
```

#### é€šç”¨ç›¸å®¹é…ç½®
```python
# æœ€å¤§ç›¸å®¹æ€§é…ç½®
model.export(
    format='onnx',
    imgsz=320,
    opset=11,              # æœ€é€šç”¨ç‰ˆæœ¬
    simplify=False,        # ä¸ç°¡åŒ–ä»¥ç¢ºä¿ç›¸å®¹æ€§
    dynamic=False,
    half=False,
    device='cpu'
)
```

### ğŸ“¦ æ‰¹æ¬¡è½‰æ›è…³æœ¬

```python
import os
from ultralytics import YOLO

def batch_convert_to_onnx(model_dir, output_dir, opset=17):
    """
    æ‰¹æ¬¡è½‰æ›å¤šå€‹ .pt æª”æ¡ˆç‚º .onnx
    
    Args:
        model_dir: åŒ…å« .pt æª”æ¡ˆçš„ç›®éŒ„
        output_dir: è¼¸å‡º .onnx æª”æ¡ˆçš„ç›®éŒ„
        opset: ONNX opset ç‰ˆæœ¬
    """
    # ç¢ºä¿è¼¸å‡ºç›®éŒ„å­˜åœ¨
    os.makedirs(output_dir, exist_ok=True)
    
    # å°‹æ‰¾æ‰€æœ‰ .pt æª”æ¡ˆ
    pt_files = [f for f in os.listdir(model_dir) if f.endswith('.pt')]
    
    print(f"æ‰¾åˆ° {len(pt_files)} å€‹æ¨¡å‹æª”æ¡ˆ")
    
    for pt_file in pt_files:
        print(f"\nè™•ç†: {pt_file}")
        
        # å®Œæ•´è·¯å¾‘
        pt_path = os.path.join(model_dir, pt_file)
        onnx_name = pt_file.replace('.pt', '.onnx')
        onnx_path = os.path.join(output_dir, onnx_name)
        
        try:
            # è¼‰å…¥ä¸¦è½‰æ›æ¨¡å‹
            model = YOLO(pt_path)
            exported_path = model.export(
                format='onnx',
                imgsz=320,
                opset=opset,
                simplify=True,
                dynamic=False,
                half=False
            )
            
            # ç§»å‹•åˆ°ç›®æ¨™ä½ç½®
            if exported_path != onnx_path:
                shutil.move(exported_path, onnx_path)
            
            print(f"âœ… æˆåŠŸ: {onnx_name}")
            
        except Exception as e:
            print(f"âŒ å¤±æ•—: {pt_file} - {str(e)}")
    
    print(f"\næ‰¹æ¬¡è½‰æ›å®Œæˆï¼")

# ä½¿ç”¨ç¯„ä¾‹
# batch_convert_to_onnx(
#     model_dir=r'path/to/models',
#     output_dir=r'path/to/onnx_models',
#     opset=17
# )
```

---

## åƒæ•¸è©³ç´°èªªæ˜

### ğŸ”§ model.export() åƒæ•¸å®Œæ•´è§£æ

| åƒæ•¸ | é¡å‹ | é è¨­å€¼ | èªªæ˜ | å»ºè­°è¨­å®š |
|------|------|--------|------|----------|
| `format` | str | 'torchscript' | è¼¸å‡ºæ ¼å¼ | **'onnx'** |
| `imgsz` | int/tuple | 640 | è¼¸å…¥åœ–ç‰‡å°ºå¯¸ | **320**ï¼ˆèˆ‡è¨“ç·´ä¸€è‡´ï¼‰ |
| `opset` | int | None | ONNX opset ç‰ˆæœ¬ | **17**(1.15.1) / **15**(1.12.1) |
| `simplify` | bool | False | æ˜¯å¦ç°¡åŒ–æ¨¡å‹ | **True**ï¼ˆæ¨è–¦ï¼‰ |
| `dynamic` | bool | False | å‹•æ…‹è¼¸å…¥å°ºå¯¸ | **False**ï¼ˆæ•ˆèƒ½æœ€ä½³ï¼‰ |
| `half` | bool | False | åŠç²¾åº¦æµ®é»æ•¸ | **False**ï¼ˆç²¾åº¦å„ªå…ˆï¼‰ |
| `int8` | bool | False | INT8 é‡åŒ– | **False**ï¼ˆé™¤ééœ€è¦ï¼‰ |
| `device` | str | None | è½‰æ›è¨­å‚™ | **'cpu'**ï¼ˆç©©å®šï¼‰ |

### ğŸ“Š åƒæ•¸é¸æ“‡å»ºè­°

#### ğŸ¯ æ•ˆèƒ½å„ªå…ˆè¨­å®š
```python
model.export(
    format='onnx',
    imgsz=320,
    opset=17,
    simplify=True,      # æœ€ä½³åŒ–æ¨¡å‹çµæ§‹
    dynamic=False,      # å›ºå®šå°ºå¯¸ä»¥æå‡é€Ÿåº¦
    half=True,          # ä½¿ç”¨åŠç²¾åº¦ï¼ˆéœ€ç¢ºèªç¡¬é«”æ”¯æ´ï¼‰
    device='cpu'
)
```

#### ğŸ¯ ç²¾åº¦å„ªå…ˆè¨­å®š
```python
model.export(
    format='onnx',
    imgsz=320,
    opset=17,
    simplify=False,     # ä¿æŒåŸå§‹çµæ§‹
    dynamic=False,
    half=False,         # ä½¿ç”¨å…¨ç²¾åº¦
    int8=False,         # ä¸é‡åŒ–
    device='cpu'
)
```

#### ğŸ¯ ç›¸å®¹æ€§å„ªå…ˆè¨­å®š
```python
model.export(
    format='onnx',
    imgsz=320,
    opset=11,           # æœ€å»£æ³›æ”¯æ´çš„ç‰ˆæœ¬
    simplify=False,     # é¿å…ç›¸å®¹æ€§å•é¡Œ
    dynamic=False,
    half=False,
    device='cpu'
)
```

---

## å¸¸è¦‹å•é¡Œèˆ‡è§£æ±ºæ–¹æ¡ˆ

### âŒ å•é¡Œ 1ï¼šOpset ç‰ˆæœ¬ä¸ç›¸å®¹

**éŒ¯èª¤è¨Šæ¯ï¼š**
```
RuntimeError: Unsupported opset version: 18
```

**è§£æ±ºæ–¹æ¡ˆï¼š**
```python
# é™ä½ opset ç‰ˆæœ¬
model.export(opset=15)  # æˆ–æ›´ä½ç‰ˆæœ¬
```

### âŒ å•é¡Œ 2ï¼šæ¨¡å‹å°ºå¯¸ä¸åŒ¹é…

**éŒ¯èª¤è¨Šæ¯ï¼š**
```
Input shape mismatch
```

**è§£æ±ºæ–¹æ¡ˆï¼š**
```python
# ç¢ºä¿ä½¿ç”¨èˆ‡è¨“ç·´æ™‚ç›¸åŒçš„å°ºå¯¸
model.export(imgsz=320)  # èˆ‡è¨“ç·´æ™‚ä¸€è‡´
```

### âŒ å•é¡Œ 3ï¼šè¨˜æ†¶é«”ä¸è¶³

**éŒ¯èª¤è¨Šæ¯ï¼š**
```
CUDA out of memory
```

**è§£æ±ºæ–¹æ¡ˆï¼š**
```python
# ä½¿ç”¨ CPU é€²è¡Œè½‰æ›
model.export(device='cpu')

# æˆ–è€…æ¸…ç† GPU è¨˜æ†¶é«”
import torch
torch.cuda.empty_cache()
```

### âŒ å•é¡Œ 4ï¼šæ¨¡å‹ç°¡åŒ–å¤±æ•—

**éŒ¯èª¤è¨Šæ¯ï¼š**
```
Model simplification failed
```

**è§£æ±ºæ–¹æ¡ˆï¼š**
```python
# é—œé–‰æ¨¡å‹ç°¡åŒ–
model.export(simplify=False)
```

### âŒ å•é¡Œ 5ï¼šå‹•æ…‹å½¢ç‹€å•é¡Œ

**éŒ¯èª¤è¨Šæ¯ï¼š**
```
Dynamic shapes not supported
```

**è§£æ±ºæ–¹æ¡ˆï¼š**
```python
# ä½¿ç”¨å›ºå®šå½¢ç‹€
model.export(dynamic=False)
```

---

## é©—è­‰èˆ‡æ¸¬è©¦

### ğŸ§ª è½‰æ›å¾Œé©—è­‰è…³æœ¬

```python
import onnx
import onnxruntime as ort
import numpy as np

def verify_onnx_model(onnx_path, input_shape=(1, 3, 320, 320)):
    """
    é©—è­‰ ONNX æ¨¡å‹æ˜¯å¦æ­£å¸¸
    
    Args:
        onnx_path: ONNX æ¨¡å‹è·¯å¾‘
        input_shape: è¼¸å…¥å¼µé‡å½¢ç‹€
    """
    print(f"é©—è­‰æ¨¡å‹: {onnx_path}")
    
    try:
        # 1. æª¢æŸ¥æ¨¡å‹çµæ§‹
        onnx_model = onnx.load(onnx_path)
        onnx.checker.check_model(onnx_model)
        print("âœ… æ¨¡å‹çµæ§‹æª¢æŸ¥é€šé")
        
        # 2. å»ºç«‹æ¨ç†æœƒè©±
        ort_session = ort.InferenceSession(onnx_path)
        print("âœ… ONNX Runtime è¼‰å…¥æˆåŠŸ")
        
        # 3. æª¢æŸ¥è¼¸å…¥è¼¸å‡º
        input_name = ort_session.get_inputs()[0].name
        input_shape_model = ort_session.get_inputs()[0].shape
        output_shape = ort_session.get_outputs()[0].shape
        
        print(f"ğŸ“Š è¼¸å…¥åç¨±: {input_name}")
        print(f"ğŸ“Š è¼¸å…¥å½¢ç‹€: {input_shape_model}")
        print(f"ğŸ“Š è¼¸å‡ºå½¢ç‹€: {output_shape}")
        
        # 4. æ¸¬è©¦æ¨ç†
        dummy_input = np.random.randn(*input_shape).astype(np.float32)
        outputs = ort_session.run(None, {input_name: dummy_input})
        
        print(f"âœ… æ¨ç†æ¸¬è©¦æˆåŠŸ")
        print(f"ğŸ“Š è¼¸å‡ºå¼µé‡å½¢ç‹€: {[out.shape for out in outputs]}")
        
        return True
        
    except Exception as e:
        print(f"âŒ é©—è­‰å¤±æ•—: {str(e)}")
        return False

# ä½¿ç”¨ç¯„ä¾‹
verify_onnx_model(r'path/to/your/model.onnx')
```

### ğŸ“Š æ•ˆèƒ½æ¯”è¼ƒæ¸¬è©¦

```python
import time
import torch
import onnxruntime as ort
from ultralytics import YOLO

def performance_comparison(pt_path, onnx_path, test_iterations=100):
    """
    æ¯”è¼ƒ PyTorch å’Œ ONNX æ¨¡å‹çš„æ¨ç†æ•ˆèƒ½
    """
    print("=== æ•ˆèƒ½æ¯”è¼ƒæ¸¬è©¦ ===")
    
    # æº–å‚™æ¸¬è©¦è³‡æ–™
    dummy_input = torch.randn(1, 3, 320, 320).float()
    
    # 1. PyTorch æ¨¡å‹æ¸¬è©¦
    print("\nğŸ”¥ PyTorch æ¨¡å‹æ¸¬è©¦")
    pt_model = YOLO(pt_path)
    pt_model.model.eval()
    
    # æš–èº«
    with torch.no_grad():
        for _ in range(10):
            _ = pt_model.model(dummy_input)
    
    # æ¸¬è©¦
    start_time = time.time()
    with torch.no_grad():
        for _ in range(test_iterations):
            _ = pt_model.model(dummy_input)
    pt_time = time.time() - start_time
    
    print(f"PyTorch å¹³å‡æ¨ç†æ™‚é–“: {pt_time/test_iterations*1000:.2f} ms")
    
    # 2. ONNX æ¨¡å‹æ¸¬è©¦
    print("\nâš¡ ONNX æ¨¡å‹æ¸¬è©¦")
    ort_session = ort.InferenceSession(onnx_path)
    input_name = ort_session.get_inputs()[0].name
    numpy_input = dummy_input.numpy()
    
    # æš–èº«
    for _ in range(10):
        _ = ort_session.run(None, {input_name: numpy_input})
    
    # æ¸¬è©¦
    start_time = time.time()
    for _ in range(test_iterations):
        _ = ort_session.run(None, {input_name: numpy_input})
    onnx_time = time.time() - start_time
    
    print(f"ONNX å¹³å‡æ¨ç†æ™‚é–“: {onnx_time/test_iterations*1000:.2f} ms")
    
    # 3. çµæœæ¯”è¼ƒ
    speedup = pt_time / onnx_time
    print(f"\nğŸ“Š æ•ˆèƒ½æå‡: {speedup:.2f}x")
    print(f"ğŸ“Š æ™‚é–“ç¯€çœ: {(1-onnx_time/pt_time)*100:.1f}%")

# ä½¿ç”¨ç¯„ä¾‹
# performance_comparison('model.pt', 'model.onnx')
```

---

## ç¸½çµèˆ‡å»ºè­°

### ğŸ¯ æœ€ä½³å¯¦è¸

1. **ç‰ˆæœ¬é¸æ“‡**
   - ç”Ÿç”¢ç’°å¢ƒï¼šä½¿ç”¨ ONNX Runtime 1.15.1 + opset 17 or 15
   - ç©©å®šç’°å¢ƒï¼šä½¿ç”¨ ONNX Runtime 1.12.1 + opset 15 or 13
   - å»£æ³›ç›¸å®¹ï¼šä½¿ç”¨ opset 11

2. **åƒæ•¸è¨­å®š**
   - å›ºå®šè¼¸å…¥å°ºå¯¸ï¼š`dynamic=False`
   - å•Ÿç”¨ç°¡åŒ–ï¼š`simplify=True`
   - ä½¿ç”¨ CPU è½‰æ›ï¼š`device='cpu'`

3. **æª”æ¡ˆç®¡ç†**
   - ä½¿ç”¨æè¿°æ€§æª”åï¼š`yolo_v8n_400.onnx`
   - ä¿ç•™åŸå§‹ .pt æª”æ¡ˆä½œç‚ºå‚™ä»½
   - å»ºç«‹ç‰ˆæœ¬æ§åˆ¶è¨˜éŒ„

### ğŸ“‹ è½‰æ›æª¢æŸ¥æ¸…å–®

- [ ] ç¢ºèª ONNX Runtime ç‰ˆæœ¬
- [ ] é¸æ“‡å°æ‡‰çš„ opset ç‰ˆæœ¬
- [ ] è¨­å®šæ­£ç¢ºçš„è¼¸å…¥å°ºå¯¸
- [ ] åŸ·è¡Œè½‰æ›ä¸¦æª¢æŸ¥éŒ¯èª¤
- [ ] é©—è­‰æ¨¡å‹è¼‰å…¥èˆ‡æ¨ç†
- [ ] é€²è¡Œæ•ˆèƒ½æ¯”è¼ƒæ¸¬è©¦
- [ ] å»ºç«‹æª”æ¡ˆå‚™ä»½èˆ‡è¨˜éŒ„
