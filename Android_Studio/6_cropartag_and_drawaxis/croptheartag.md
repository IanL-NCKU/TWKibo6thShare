# ğŸ“¦ **ç¨‹å¼ç¢¼**
```java
package jp.jaxa.iss.kibo.rpc.sampleapk;

import jp.jaxa.iss.kibo.rpc.api.KiboRpcService;

import gov.nasa.arc.astrobee.types.Point;
import gov.nasa.arc.astrobee.types.Quaternion;

//import org.opencv.core.Mat;

// new imports
import android.util.Log;

import java.util.List;
import java.util.ArrayList;


// new OpenCV imports
import org.opencv.aruco.Dictionary;
import org.opencv.aruco.Aruco;
import org.opencv.core.*;
// OpenCV Core imports
//import org.opencv.core.CvType;
//import org.opencv.core.Scalar;
//import org.opencv.core.Rect;
//import org.opencv.core.Point3;
//import org.opencv.core.MatOfPoint3f;
//import org.opencv.core.MatOfPoint2f;
//import org.opencv.core.MatOfDouble;

// OpenCV Image Processing
import org.opencv.imgproc.Imgproc;

// OpenCV Calibration
import org.opencv.calib3d.Calib3d;
import gov.nasa.arc.astrobee.Result;
/**
 * Class meant to handle commands from the Ground Data System and execute them in Astrobee.
 */

public class YourService extends KiboRpcService {

    // The TAG is used for logging.
    // You can use it to check the log in the Android Studio.
    private final String TAG = this.getClass().getSimpleName();

    @Override
    protected void runPlan1(){

        // Log the start of the mission.
        Log.i(TAG, "Start mission");
        // The mission starts.
        api.startMission();
        

        // Move to a point.
        Point point = new Point(10.9d, -9.92284d, 5.195d);
        Quaternion quaternion = new Quaternion(0f, 0f, -0.707f, 0.707f);
        api.moveTo(point, quaternion, false);

        // Get a camera image.
        Mat image = api.getMatNavCam();
        // Save the image to a file.
        api.saveMatImage(image, "test.png");


        /* ******************************************************************************** */
        /* Write your code to recognize the type and number of landmark items in each area! */
        /* If there is a treasure item, remember it.                                        */
        /* ******************************************************************************** */

        // 
        /**
         * Retrieves a predefined Aruco dictionary for 6x6 markers containing 250 distinct patterns.
         * This dictionary is used for detecting and tracking Aruco markers in images.
         *
         * The call to Aruco.getPredefinedDictionary(Aruco.DICT_6X6_250) selects a standard set of marker patterns,
         * making it easier to consistently identify markers during image processing.
         */
        Dictionary dictionary = Aruco.getPredefinedDictionary(Aruco.DICT_5X5_250);
        
        // Detect markers in the image using the specified dictionary.
        // The detectMarkers function analyzes the image and identifies the locations of Aruco markers.
        // The detected markers are stored in the corners list.
        // The corners list contains the coordinates of the detected markers in the image.
        
        List<Mat> corners = new ArrayList<>();
        Mat ids = new Mat();
        // The ids list contains the IDs of the detected markers.
        Aruco.detectMarkers(image, dictionary, corners, ids);

        if (corners.size() > 0) {
            // Get camera parameters
            double[][] intrinsics = api.getNavCamIntrinsics();
            Mat cameraMatrix = new Mat(3, 3, CvType.CV_64F);
            Mat distCoeffs = new Mat(1, 5, CvType.CV_64F);
            
            // Fill camera matrix
            cameraMatrix.put(0, 0, intrinsics[0]);
            distCoeffs.put(0, 0, intrinsics[1]);
            distCoeffs.convertTo(distCoeffs, CvType.CV_64F);

            
            // Estimate pose for each marker
            Mat rvecs = new Mat();
            Mat tvecs = new Mat();
            
            // Marker size in meters (adjust according to your actual marker size)
            float markerLength = 0.05f; // 5cm markers
            
            Aruco.estimatePoseSingleMarkers(corners, markerLength, cameraMatrix, distCoeffs, rvecs, tvecs);
            
            // Draw markers and coordinate frames
            Mat imageWithFrame = image.clone();
            Mat imagewithcroparea = image.clone();

            Aruco.drawDetectedMarkers(imageWithFrame, corners, ids);
            
            // type the number of corners in log
            Log.i(TAG, "Detected " + corners.size() + " markers.");
            
            // Draw coordinate frame for each marker
            for (int i = 0; i < corners.size(); i++) {
                
                // extract the corners name variable "currentCorners"
                Mat currentCorners = corners.get(i);
                

                Mat UndistortImg = new Mat();

                if (rvecs.rows() > 0 && tvecs.rows() > 0) {
                    Mat rvec = new Mat(3, 1, CvType.CV_64F);
                    Mat tvec = new Mat(3, 1, CvType.CV_64F);
                    
                    rvecs.row(i).copyTo(rvec);
                    tvecs.row(i).copyTo(tvec);
                    
                    Imgproc.cvtColor(imageWithFrame, imageWithFrame, Imgproc.COLOR_GRAY2RGB);
                    // Simply draw the coordinate frame
                    Aruco.drawAxis(imageWithFrame, cameraMatrix, distCoeffs, rvec, tvec, 0.1f); // 0.1m axis length

                    // corners.get(i) is Mat we need to convert it to MatOfPoint2f
                    MatOfPoint2f cornerPoints = new MatOfPoint2f(currentCorners);

                    // check corner[0] and crop region
                    checkCornerAndCropRegion(imagewithcroparea, cameraMatrix, distCoeffs, rvec, tvec, cornerPoints);
                    api.saveMatImage(imagewithcroparea, "marker_" + i + "_crop_area.png");
                    // drawCropArea(imagewithcroparea, corners.get(i).toArray());


                    // Release individual vectors
                    cornerPoints.release();
                    rvec.release();
                    tvec.release();
                }


                // Extract rotation and translation vectors for this marker
                // rvecs.row(i).copyTo(rvec);
                // tvecs.row(i).copyTo(tvec);

                // Draw coordinate frame (X=red, Y=green, Z=blue)
                // drawCoordinateFrame(imageWithFrame, cameraMatrix, distCoeffs, rvec, tvec, markerLength);
                
                // Crop region around the marker
                Mat croppedRegion = cropMarkerRegion(image, corners.get(i));
                
                // Save cropped image for debugging
                api.saveMatImage(croppedRegion, "marker_" + i + "_cropped.png"); 
                // see what color type of imageWithFrame is
                Log.i(TAG, "Image with frame type: " + imageWithFrame.type());

                // make imageWithFrame from GRAY to RGB
                
                // Save image with drawn frames
                api.saveMatImage(imageWithFrame, "marker_" + i + "_with_frame.png");

                
                Calib3d.undistort(image, UndistortImg, cameraMatrix, distCoeffs);

                // Save undistorted image for debugging
                api.saveMatImage(UndistortImg, "marker_" + i + "_undistorted.png");


                // Clean up individual vectors
                // rvec.release();
                // tvec.release();
                croppedRegion.release();
                UndistortImg.release();
                imageWithFrame.release();

            }

            // Clean up
            rvecs.release();
            tvecs.release();
            // UndistortImg.release();
            cameraMatrix.release();
            distCoeffs.release();
        }

        // Clean up
        ids.release();
        for (Mat corner : corners) {
            corner.release();
        }
        
        
        // When you recognize landmark items, letâ€™s set the type and number.
        api.setAreaInfo(1, "item_name", 1);

        /* **************************************************** */
        /* Let's move to each area and recognize the items. */
        /* **************************************************** */

        // When you move to the front of the astronaut, report the rounding completion.
        point = new Point(11.143d, -6.7607d, 4.9654d);
        quaternion = new Quaternion(0f, 0f, 0.707f, 0.707f);
        api.moveTo(point, quaternion, false);
        api.reportRoundingCompletion();

        /* ********************************************************** */
        /* Write your code to recognize which target item the astronaut has. */
        /* ********************************************************** */

        // Let's notify the astronaut when you recognize it.
        api.notifyRecognitionItem();

        /* ******************************************************************************************************* */
        /* Write your code to move Astrobee to the location of the target item (what the astronaut is looking for) */
        /* ******************************************************************************************************* */

        // Take a snapshot of the target item.
        api.takeTargetItemSnapshot();
    }

    @Override
    protected void runPlan2(){
       // write your plan 2 here.
    }

    @Override
    protected void runPlan3(){
        // write your plan 3 here.
    }



    private void checkCornerAndCropRegion(Mat image, Mat cameraMatrix, Mat distCoeffs, 
                                        Mat rvec, Mat tvec, MatOfPoint2f corners) {
        try {
            // 1. Check if corner[0] is close to expected 3D position (-0.025, 0.025, 0)
            org.opencv.core.Point[] cornerPoints = corners.toArray();
            if (cornerPoints.length > 0) {
                // Project expected 3D point to 2D
                org.opencv.core.Point3[] expectedPoint3D = {new org.opencv.core.Point3(-0.025, 0.025, 0)};
                MatOfPoint3f expectedPointMat = new MatOfPoint3f(expectedPoint3D);
                MatOfPoint2f projectedExpected = new MatOfPoint2f();
                
                // Convert distortion coefficients
                double[] distData = new double[5];
                distCoeffs.get(0, 0, distData);
                MatOfDouble distCoeffsDouble = new MatOfDouble();
                distCoeffsDouble.fromArray(distData);
                
                // Project expected point
                Calib3d.projectPoints(expectedPointMat, rvec, tvec, cameraMatrix, distCoeffsDouble, projectedExpected);
                org.opencv.core.Point[] projectedPoints = projectedExpected.toArray();
                
                if (projectedPoints.length > 0) {
                    org.opencv.core.Point expectedCorner = projectedPoints[0];
                    org.opencv.core.Point actualCorner = cornerPoints[0];
                    
                    // Calculate distance between expected and actual corner
                    // double distance = Math.sqrt(Math.pow(expectedCorner.x - actualCorner.x, 2) + 
                    //                         Math.pow(expectedCorner.y - actualCorner.y, 2));
                    
                    double distance = getdistance(expectedCorner, actualCorner);
                    // Check if close (within 10 pixels tolerance)
                    if (distance > 10.0) {
                        // Log the real 3D position of corner[0]
                        // To get 3D position, we need to reverse project (assuming z=0 for simplicity)
                        Log.i(TAG, String.format("Corner[0] not at expected position. Detected at 2D: (%.2f, %.2f), Expected 2D: (%.2f, %.2f), Distance: %.2f pixels", 
                                actualCorner.x, actualCorner.y, expectedCorner.x, expectedCorner.y, distance));
                    } else {
                        Log.i(TAG, "Corner[0] is close to expected position (-2.5, 2.5, 0)");
                    }
                }
                
                // Clean up
                expectedPointMat.release();
                projectedExpected.release();
                distCoeffsDouble.release();
            }
            
            // 2. Project the 4 crop area corners to 2D
            // Manually adjustment
            org.opencv.core.Point3[] cropCorners3D = {
                new org.opencv.core.Point3(-0.0325, 0.0375, 0),    // Top-left
                new org.opencv.core.Point3(-0.2325, 0.0375, 0),   // Top-right  
                new org.opencv.core.Point3(-0.2325, -0.1125, 0), // Bottom-right
                new org.opencv.core.Point3(-0.0325, -0.1125, 0)   // Bottom-left
            };
            
            MatOfPoint3f cropCornersMat = new MatOfPoint3f(cropCorners3D);
            MatOfPoint2f cropCorners2D = new MatOfPoint2f();
            
            // Convert distortion coefficients again
            double[] distData = new double[5];
            distCoeffs.get(0, 0, distData);
            MatOfDouble distCoeffsDouble = new MatOfDouble();
            distCoeffsDouble.fromArray(distData);
            
            // Project crop corners to 2D
            Calib3d.projectPoints(cropCornersMat, rvec, tvec, cameraMatrix, distCoeffsDouble, cropCorners2D);
            org.opencv.core.Point[] cropPoints2D = cropCorners2D.toArray();
            
            if (cropPoints2D.length == 4) {
                // 3. Create perspective transformation and crop
                cropAndSaveRegion(image, cropPoints2D);
            }
            
            // Clean up
            cropCornersMat.release();
            cropCorners2D.release();
            distCoeffsDouble.release();
            
        } catch (Exception e) {
            Log.e(TAG, "Error in checkCornerAndCropRegion: " + e.getMessage());
        }
    }

    private void cropAndSaveRegion(Mat image, org.opencv.core.Point[] cropPoints2D) {
        try {
            // Define destination points for 640x480 rectangle
            org.opencv.core.Point[] dstPoints = {
                new org.opencv.core.Point(0, 0),       // Top-left
                new org.opencv.core.Point(639, 0),     // Top-right
                new org.opencv.core.Point(639, 479),   // Bottom-right
                new org.opencv.core.Point(0, 479)      // Bottom-left
            };
            
            // Create source and destination point matrices
            MatOfPoint2f srcPointsMat = new MatOfPoint2f(cropPoints2D);
            MatOfPoint2f dstPointsMat = new MatOfPoint2f(dstPoints);
            
            // Calculate perspective transformation matrix
            Mat perspectiveMatrix = Imgproc.getPerspectiveTransform(srcPointsMat, dstPointsMat);
            
            // Apply perspective transformation
            Mat croppedImage = new Mat();
            Imgproc.warpPerspective(image, croppedImage, perspectiveMatrix, new Size(640, 480));
            
            // Save the cropped image
            api.saveMatImage(croppedImage, "cropped_region_640x480.png");
            Log.i(TAG, "Cropped region saved as 640x480 image");
            
            // Optional: Draw the crop area on original image for visualization
            drawCropArea(image, cropPoints2D);
            
            // Clean up
            srcPointsMat.release();
            dstPointsMat.release();
            perspectiveMatrix.release();
            croppedImage.release();
            
        } catch (Exception e) {
            Log.e(TAG, "Error cropping region: " + e.getMessage());
        }
    }

    // ------------------------------------------------------------------------------------

    //-------------------------------------------------------------------------------------

    /**
     * Crops a region around the detected marker with some padding
     */
    private Mat cropMarkerRegion(Mat image, Mat markerCorners) {
        // Get the four corners of the marker
        float[] cornerData = new float[(int)(markerCorners.total() * markerCorners.channels())];
        markerCorners.get(0, 0, cornerData);
        
        // Find bounding rectangle
        float minX = Float.MAX_VALUE, minY = Float.MAX_VALUE;
        float maxX = Float.MIN_VALUE, maxY = Float.MIN_VALUE;
        
        for (int i = 0; i < cornerData.length; i += 2) {
            float x = cornerData[i];
            float y = cornerData[i + 1];
            
            minX = Math.min(minX, x);
            maxX = Math.max(maxX, x);
            minY = Math.min(minY, y);
            maxY = Math.max(maxY, y);
        }
        
        // Add padding (20% of marker size)
        float padding = Math.max(maxX - minX, maxY - minY) * 0.2f;
        
        int x = Math.max(0, (int)(minX - padding));
        int y = Math.max(0, (int)(minY - padding));
        int width = Math.min(image.cols() - x, (int)(maxX - minX + 2 * padding));
        int height = Math.min(image.rows() - y, (int)(maxY - minY + 2 * padding));
        
        // Create rectangle and crop
        Rect cropRect = new Rect(x, y, width, height);
        Mat croppedImage = new Mat(image, cropRect);
        
        return croppedImage.clone();
    }

    private void drawCropArea(Mat image, org.opencv.core.Point[] cropPoints2D) {
        // turn the image to RGB
        Imgproc.cvtColor(image, image, Imgproc.COLOR_GRAY2RGB);
        // Draw the crop area outline on the original image
        for (int i = 0; i < cropPoints2D.length; i++) {
            org.opencv.core.Point pt1 = cropPoints2D[i];
            org.opencv.core.Point pt2 = cropPoints2D[(i + 1) % cropPoints2D.length];
            Imgproc.line(image, pt1, pt2, new Scalar(255, 255, 0), 2); // Yellow lines
            // input to log
            Log.i(TAG, String.format("Crop Point %d: (%.2f, %.2f)", i, pt1.x, pt1.y));
        }
        
        // Add corner labels
        for (int i = 0; i < cropPoints2D.length; i++) {
            Imgproc.putText(image, String.valueOf(i), cropPoints2D[i], 
                        Imgproc.FONT_HERSHEY_SIMPLEX, 0.5, new Scalar(255, 255, 0), 2);
        }
    }

    private Result sureMoveToPoint(Point point, Quaternion quaternion, boolean printRobotPosition, int maxRetries) {
        Result result = api.moveTo(point, quaternion, printRobotPosition);
        
        int retryCount = 0;
        while (!result.hasSucceeded() && retryCount < maxRetries) {
            result = api.moveTo(point, quaternion, true); // Use true for retries
            retryCount++;
        }
        
        return result;
    }


    private double getdistance(org.opencv.core.Point p1, org.opencv.core.Point p2) {
        // Calculate the distance between two points using the Euclidean distance formula
        return Math.sqrt(Math.pow(p2.x - p1.x, 2) + Math.pow(p2.y - p1.y, 2));
    }

    // You can add your method.
    private String yourMethod(){
        return "your method";
    }
}

```


## ğŸ“¦ **ç¨‹å¼åŒ…èˆ‡åŒ¯å…¥æ¨¡çµ„**

### **åŸºç¤åŒ¯å…¥**
```java
package jp.jaxa.iss.kibo.rpc.sampleapk;

import jp.jaxa.iss.kibo.rpc.api.KiboRpcService;
import gov.nasa.arc.astrobee.types.Point;
import gov.nasa.arc.astrobee.types.Quaternion;
import android.util.Log;
import java.util.List;
import java.util.ArrayList;
```

**åŠŸèƒ½èªªæ˜ï¼š**
- å®šç¾©ç¨‹å¼åŒ…åç¨±
- åŒ¯å…¥Astrobeeæ©Ÿå™¨äººæ§åˆ¶API
- åŒ¯å…¥Androidæ—¥èªŒåŠŸèƒ½
- åŒ¯å…¥Javaé›†åˆé¡åˆ¥ï¼Œç”¨æ–¼å„²å­˜æª¢æ¸¬åˆ°çš„æ¨™è¨˜

### **OpenCVé›»è…¦è¦–è¦ºå‡½å¼åº«**
```java
import org.opencv.aruco.Dictionary;
import org.opencv.aruco.Aruco;
import org.opencv.core.*;
import org.opencv.imgproc.Imgproc;
import org.opencv.calib3d.Calib3d;
import gov.nasa.arc.astrobee.Result;
```

**åŠŸèƒ½èªªæ˜ï¼š**
- `Dictionary` - ArUcoæ¨™è¨˜å­—å…¸
- `Aruco` - ArUcoæ¨™è¨˜æª¢æ¸¬åŠŸèƒ½
- `core.*` - OpenCVæ ¸å¿ƒåŠŸèƒ½ï¼ˆMat, Point, Sizeç­‰ï¼‰
- `Imgproc` - å½±åƒè™•ç†åŠŸèƒ½ï¼ˆé¡è‰²è½‰æ›ã€é€è¦–è®Šæ›ç­‰ï¼‰
- `Calib3d` - ç›¸æ©Ÿæ¨™å®šå’Œ3Då¹¾ä½•é‹ç®—
- `Result` - APIå‘¼å«çµæœ

---

## ğŸš€ **runPlan1() - ä¸»è¦ä»»å‹™åŸ·è¡Œæ–¹æ³•**

### **ä»»å‹™åˆå§‹åŒ–èˆ‡æ©Ÿå™¨äººå®šä½**
```java
@Override
protected void runPlan1(){
    Log.i(TAG, "Start mission");
    api.startMission();
    
    Point point = new Point(10.9d, -9.92284d, 5.195d);
    Quaternion quaternion = new Quaternion(0f, 0f, -0.707f, 0.707f);
    api.moveTo(point, quaternion, false);
    
    Mat image = api.getMatNavCam();
    api.saveMatImage(image, "test.png");
}
```

**åŠŸèƒ½èªªæ˜ï¼š**
- è¨˜éŒ„ä»»å‹™é–‹å§‹æ—¥èªŒä¸¦å•Ÿå‹•ä»»å‹™
- ç§»å‹•æ©Ÿå™¨äººåˆ°åˆå§‹è§€å¯Ÿä½ç½®
- ç²å–å°èˆªç›¸æ©Ÿå½±åƒä¸¦å„²å­˜ç‚ºæ¸¬è©¦æª”æ¡ˆ

### **ArUcoæ¨™è¨˜æª¢æ¸¬æ ¸å¿ƒé‚è¼¯**
```java
Dictionary dictionary = Aruco.getPredefinedDictionary(Aruco.DICT_5X5_250);
List<Mat> corners = new ArrayList<>();
Mat ids = new Mat();
Aruco.detectMarkers(image, dictionary, corners, ids);
```

**åŠŸèƒ½èªªæ˜ï¼š**
- å»ºç«‹5x5å¤§å°çš„ArUcoæ¨™è¨˜å­—å…¸ï¼ŒåŒ…å«250å€‹ä¸åŒçš„æ¨™è¨˜åœ–æ¡ˆ
- åœ¨å½±åƒä¸­æª¢æ¸¬ArUcoæ¨™è¨˜
- `corners` å„²å­˜æª¢æ¸¬åˆ°çš„æ¨™è¨˜è§’é»åº§æ¨™
- `ids` å„²å­˜æ¨™è¨˜çš„IDç·¨è™Ÿ

### **ç›¸æ©Ÿåƒæ•¸è¨­å®šèˆ‡å§¿æ…‹ä¼°è¨ˆ**
```java
if (corners.size() > 0) {
    double[][] intrinsics = api.getNavCamIntrinsics();
    Mat cameraMatrix = new Mat(3, 3, CvType.CV_64F);
    Mat distCoeffs = new Mat(1, 5, CvType.CV_64F);
    
    cameraMatrix.put(0, 0, intrinsics[0]);
    distCoeffs.put(0, 0, intrinsics[1]);
    
    Mat rvecs = new Mat();
    Mat tvecs = new Mat();
    float markerLength = 0.05f; // 5cm markers
    
    Aruco.estimatePoseSingleMarkers(corners, markerLength, cameraMatrix, distCoeffs, rvecs, tvecs);
}
```

**åŠŸèƒ½èªªæ˜ï¼š**
- æª¢æŸ¥æ˜¯å¦æª¢æ¸¬åˆ°æ¨™è¨˜
- ç²å–ç›¸æ©Ÿå…§åƒæ•¸ï¼ˆç„¦è·ã€ä¸»é»ã€ç•¸è®Šä¿‚æ•¸ï¼‰
- å»ºç«‹ç›¸æ©ŸçŸ©é™£å’Œç•¸è®Šä¿‚æ•¸çŸ©é™£
- ä¼°è¨ˆæ¯å€‹æ¨™è¨˜çš„3Då§¿æ…‹ï¼ˆæ—‹è½‰å’Œå¹³ç§»å‘é‡ï¼‰

### **æ¨™è¨˜è™•ç†èˆ‡å¯è¦–åŒ–**
```java
for (int i = 0; i < corners.size(); i++) {
    Mat currentCorners = corners.get(i);
    
    if (rvecs.rows() > 0 && tvecs.rows() > 0) {
        Mat rvec = new Mat(3, 1, CvType.CV_64F);
        Mat tvec = new Mat(3, 1, CvType.CV_64F);
        
        rvecs.row(i).copyTo(rvec);
        tvecs.row(i).copyTo(tvec);
        
        Imgproc.cvtColor(imageWithFrame, imageWithFrame, Imgproc.COLOR_GRAY2RGB);
        Aruco.drawAxis(imageWithFrame, cameraMatrix, distCoeffs, rvec, tvec, 0.1f);
        
        MatOfPoint2f cornerPoints = new MatOfPoint2f(currentCorners);
        checkCornerAndCropRegion(imagewithcroparea, cameraMatrix, distCoeffs, rvec, tvec, cornerPoints);
    }
}
```

**åŠŸèƒ½èªªæ˜ï¼š**
- éæ­·æ¯å€‹æª¢æ¸¬åˆ°çš„æ¨™è¨˜
- æå–ç•¶å‰æ¨™è¨˜çš„æ—‹è½‰å’Œå¹³ç§»å‘é‡
- è½‰æ›å½±åƒç‚ºRGBæ ¼å¼ä¸¦ç¹ªè£½3Dåº§æ¨™è»¸
- å‘¼å«ç²¾å¯†è£å‰ªæ–¹æ³•è™•ç†æ¨™è¨˜å€åŸŸ

---

## ğŸ”§ **checkCornerAndCropRegion() - æª¢æŸ¥è§’é»ä½ç½®ä¸¦è£å‰ªå€åŸŸ**

```java
private void checkCornerAndCropRegion(Mat image, Mat cameraMatrix, Mat distCoeffs, 
                                    Mat rvec, Mat tvec, MatOfPoint2f corners) {
    try {
        // 1. é©—è­‰è§’é»ä½ç½®ç²¾åº¦
        org.opencv.core.Point[] cornerPoints = corners.toArray();
        if (cornerPoints.length > 0) {
            org.opencv.core.Point3[] expectedPoint3D = {new org.opencv.core.Point3(-0.025, 0.025, 0)};
            MatOfPoint3f expectedPointMat = new MatOfPoint3f(expectedPoint3D);
            MatOfPoint2f projectedExpected = new MatOfPoint2f();
            
            Calib3d.projectPoints(expectedPointMat, rvec, tvec, cameraMatrix, distCoeffsDouble, projectedExpected);
            
            double distance = getdistance(expectedCorner, actualCorner);
            if (distance > 10.0) {
                Log.i(TAG, "Corner[0] not at expected position...");
            } else {
                Log.i(TAG, "Corner[0] is close to expected position (-2.5, 2.5, 0)");
            }
        }
        
        // 2. å®šç¾©è£å‰ªå€åŸŸçš„3Dè§’é»
        org.opencv.core.Point3[] cropCorners3D = {
            new org.opencv.core.Point3(-0.0325, 0.0375, 0),    // Top-left
            new org.opencv.core.Point3(-0.2325, 0.0375, 0),   // Top-right  
            new org.opencv.core.Point3(-0.2325, -0.1125, 0),  // Bottom-right
            new org.opencv.core.Point3(-0.0325, -0.1125, 0)   // Bottom-left
        };
        
        // 3. æŠ•å½±åˆ°2Dä¸¦åŸ·è¡Œè£å‰ª
        Calib3d.projectPoints(cropCornersMat, rvec, tvec, cameraMatrix, distCoeffsDouble, cropCorners2D);
        cropAndSaveRegion(image, cropPoints2D);
        
    } catch (Exception e) {
        Log.e(TAG, "Error in checkCornerAndCropRegion: " + e.getMessage());
    }
}
```

**åŠŸèƒ½èªªæ˜ï¼š**
- **ç²¾åº¦é©—è­‰**ï¼šæª¢æŸ¥æª¢æ¸¬åˆ°çš„è§’é»æ˜¯å¦æ¥è¿‘é æœŸçš„3Dä½ç½®ï¼ˆ-2.5cm, 2.5cm, 0ï¼‰
- **3Dåˆ°2DæŠ•å½±**ï¼šå°‡é æœŸçš„3Dåº§æ¨™é»æŠ•å½±åˆ°2Då½±åƒåº§æ¨™é€²è¡Œæ¯”è¼ƒ
- **è£å‰ªå€åŸŸå®šç¾©**ï¼šå®šç¾©å››å€‹3Dè§’é»ä½œç‚ºè£å‰ªå€åŸŸçš„é‚Šç•Œ
- **åº§æ¨™è½‰æ›**ï¼šå°‡3Dè£å‰ªå€åŸŸæŠ•å½±åˆ°2Då½±åƒåº§æ¨™
- **éŒ¯èª¤è™•ç†**ï¼šæ•ç²ä¸¦è¨˜éŒ„è™•ç†éç¨‹ä¸­çš„ç•°å¸¸

---

## âœ‚ï¸ **cropAndSaveRegion() - è£å‰ªä¸¦ä¿å­˜å€åŸŸ**

```java
private void cropAndSaveRegion(Mat image, org.opencv.core.Point[] cropPoints2D) {
    try {
        // å®šç¾©ç›®æ¨™çŸ©å½¢ï¼ˆ640x480åƒç´ ï¼‰
        org.opencv.core.Point[] dstPoints = {
            new org.opencv.core.Point(0, 0),       // Top-left
            new org.opencv.core.Point(639, 0),     // Top-right
            new org.opencv.core.Point(639, 479),   // Bottom-right
            new org.opencv.core.Point(0, 479)      // Bottom-left
        };
        
        // è¨ˆç®—é€è¦–è®Šæ›çŸ©é™£
        MatOfPoint2f srcPointsMat = new MatOfPoint2f(cropPoints2D);
        MatOfPoint2f dstPointsMat = new MatOfPoint2f(dstPoints);
        Mat perspectiveMatrix = Imgproc.getPerspectiveTransform(srcPointsMat, dstPointsMat);
        
        // åŸ·è¡Œé€è¦–è®Šæ›
        Mat croppedImage = new Mat();
        Imgproc.warpPerspective(image, croppedImage, perspectiveMatrix, new Size(640, 480));
        
        // ä¿å­˜è£å‰ªå¾Œçš„å½±åƒ
        api.saveMatImage(croppedImage, "cropped_region_640x480.png");
        Log.i(TAG, "Cropped region saved as 640x480 image");
        
        // å¯è¦–åŒ–è£å‰ªå€åŸŸ
        drawCropArea(image, cropPoints2D);
        
    } catch (Exception e) {
        Log.e(TAG, "Error cropping region: " + e.getMessage());
    }
}
```

**åŠŸèƒ½èªªæ˜ï¼š**
- **ç›®æ¨™çŸ©å½¢å®šç¾©**ï¼šè¨­å®š640x480åƒç´ çš„æ¨™æº–çŸ©å½¢ä½œç‚ºè¼¸å‡ºæ ¼å¼
- **é€è¦–è®Šæ›çŸ©é™£è¨ˆç®—**ï¼šæ ¹æ“šæºé»å’Œç›®æ¨™é»è¨ˆç®—è®Šæ›çŸ©é™£
- **å½±åƒçŸ¯æ­£**ï¼šåŸ·è¡Œé€è¦–è®Šæ›ï¼Œå°‡å‚¾æ–œçš„å½±åƒå€åŸŸçŸ¯æ­£ç‚ºæ­£çŸ©å½¢
- **çµæœä¿å­˜**ï¼šå°‡è™•ç†å¾Œçš„å½±åƒä¿å­˜ç‚ºæª”æ¡ˆ
- **å¯è¦–åŒ–**ï¼šåœ¨åŸå§‹å½±åƒä¸Šç¹ªè£½è£å‰ªå€åŸŸé‚Šç•Œ

---

## ğŸ“ **cropMarkerRegion() - è£å‰ªæ¨™è¨˜å€åŸŸ**

```java
private Mat cropMarkerRegion(Mat image, Mat markerCorners) {
    // æå–æ¨™è¨˜è§’é»æ•¸æ“š
    float[] cornerData = new float[(int)(markerCorners.total() * markerCorners.channels())];
    markerCorners.get(0, 0, cornerData);
    
    // æ‰¾å‡ºåŒ…åœæ¨™è¨˜çš„æœ€å°çŸ©å½¢
    float minX = Float.MAX_VALUE, minY = Float.MAX_VALUE;
    float maxX = Float.MIN_VALUE, maxY = Float.MIN_VALUE;
    
    for (int i = 0; i < cornerData.length; i += 2) {
        float x = cornerData[i];
        float y = cornerData[i + 1];
        
        minX = Math.min(minX, x);
        maxX = Math.max(maxX, x);
        minY = Math.min(minY, y);
        maxY = Math.max(maxY, y);
    }
    
    // æ·»åŠ 20%çš„é‚Šè·
    float padding = Math.max(maxX - minX, maxY - minY) * 0.2f;
    
    int x = Math.max(0, (int)(minX - padding));
    int y = Math.max(0, (int)(minY - padding));
    int width = Math.min(image.cols() - x, (int)(maxX - minX + 2 * padding));
    int height = Math.min(image.rows() - y, (int)(maxY - minY + 2 * padding));
    
    // å»ºç«‹è£å‰ªçŸ©å½¢ä¸¦åŸ·è¡Œè£å‰ª
    Rect cropRect = new Rect(x, y, width, height);
    Mat croppedImage = new Mat(image, cropRect);
    
    return croppedImage.clone();
}
```

**åŠŸèƒ½èªªæ˜ï¼š**
- **è§’é»æ•¸æ“šæå–**ï¼šå¾Matæ ¼å¼ä¸­æå–æ¨™è¨˜çš„å››å€‹è§’é»åº§æ¨™
- **é‚Šç•ŒçŸ©å½¢è¨ˆç®—**ï¼šæ‰¾å‡ºåŒ…åœæ‰€æœ‰è§’é»çš„æœ€å°çŸ©å½¢
- **é‚Šè·æ·»åŠ **ï¼šç‚ºè£å‰ªå€åŸŸæ·»åŠ 20%çš„é‚Šè·ä»¥ç¢ºä¿å®Œæ•´æ€§
- **é‚Šç•Œæª¢æŸ¥**ï¼šç¢ºä¿è£å‰ªå€åŸŸä¸è¶…å‡ºå½±åƒé‚Šç•Œ
- **çŸ©å½¢è£å‰ª**ï¼šå»ºç«‹è£å‰ªçŸ©å½¢ä¸¦è¿”å›è£å‰ªå¾Œçš„å½±åƒ

---

## ğŸ¨ **drawCropArea() - ç¹ªè£½è£å‰ªå€åŸŸ**

```java
private void drawCropArea(Mat image, org.opencv.core.Point[] cropPoints2D) {
    // è½‰æ›å½±åƒç‚ºRGBæ ¼å¼
    Imgproc.cvtColor(image, image, Imgproc.COLOR_GRAY2RGB);
    
    // ç¹ªè£½è£å‰ªå€åŸŸè¼ªå»“
    for (int i = 0; i < cropPoints2D.length; i++) {
        org.opencv.core.Point pt1 = cropPoints2D[i];
        org.opencv.core.Point pt2 = cropPoints2D[(i + 1) % cropPoints2D.length];
        Imgproc.line(image, pt1, pt2, new Scalar(255, 255, 0), 2); // é»ƒè‰²ç·šæ¢
        Log.i(TAG, String.format("Crop Point %d: (%.2f, %.2f)", i, pt1.x, pt1.y));
    }
    
    // æ·»åŠ è§’é»æ¨™ç±¤
    for (int i = 0; i < cropPoints2D.length; i++) {
        Imgproc.putText(image, String.valueOf(i), cropPoints2D[i], 
                    Imgproc.FONT_HERSHEY_SIMPLEX, 0.5, new Scalar(255, 255, 0), 2);
    }
}
```

**åŠŸèƒ½èªªæ˜ï¼š**
- **æ ¼å¼è½‰æ›**ï¼šå°‡ç°åº¦å½±åƒè½‰æ›ç‚ºRGBæ ¼å¼ä»¥æ”¯æ´å½©è‰²ç¹ªè£½
- **è¼ªå»“ç¹ªè£½**ï¼šç”¨é»ƒè‰²ç·šæ¢é€£æ¥å››å€‹è£å‰ªå€åŸŸè§’é»å½¢æˆå°é–‰è¼ªå»“
- **åº§æ¨™è¨˜éŒ„**ï¼šå°‡æ¯å€‹è§’é»çš„åº§æ¨™è¨˜éŒ„åˆ°æ—¥èªŒä¸­
- **æ¨™ç±¤æ·»åŠ **ï¼šåœ¨æ¯å€‹è§’é»ä½ç½®æ·»åŠ æ•¸å­—æ¨™ç±¤ä¾¿æ–¼è­˜åˆ¥

---

## ğŸ¯ **sureMoveToPoint() - ç¢ºä¿ç§»å‹•åˆ°æŒ‡å®šé»**

```java
private Result sureMoveToPoint(Point point, Quaternion quaternion, boolean printRobotPosition, int maxRetries) {
    Result result = api.moveTo(point, quaternion, printRobotPosition);
    
    int retryCount = 0;
    while (!result.hasSucceeded() && retryCount < maxRetries) {
        result = api.moveTo(point, quaternion, true); // é‡è©¦æ™‚ä½¿ç”¨true
        retryCount++;
    }
    
    return result;
}
```

**åŠŸèƒ½èªªæ˜ï¼š**
- **åˆå§‹ç§»å‹•**ï¼šé¦–æ¬¡å˜—è©¦ç§»å‹•åˆ°æŒ‡å®šä½ç½®
- **å¤±æ•—é‡è©¦**ï¼šå¦‚æœç§»å‹•å¤±æ•—ï¼Œè‡ªå‹•é‡è©¦ç›´åˆ°æˆåŠŸæˆ–é”åˆ°æœ€å¤§é‡è©¦æ¬¡æ•¸
- **ç‹€æ…‹è¿½è¹¤**ï¼šè¿½è¹¤é‡è©¦æ¬¡æ•¸é¿å…ç„¡é™è¿´åœˆ
- **çµæœå›å‚³**ï¼šå›å‚³æœ€çµ‚çš„ç§»å‹•çµæœ

---

## ğŸ“ **getdistance() - è¨ˆç®—å…©é»è·é›¢**

```java
private double getdistance(org.opencv.core.Point p1, org.opencv.core.Point p2) {
    return Math.sqrt(Math.pow(p2.x - p1.x, 2) + Math.pow(p2.y - p1.y, 2));
}
```

**åŠŸèƒ½èªªæ˜ï¼š**
- **æ­å¹¾é‡Œå¾—è·é›¢è¨ˆç®—**ï¼šä½¿ç”¨æ¨™æº–çš„è·é›¢å…¬å¼è¨ˆç®—å…©é»é–“çš„ç›´ç·šè·é›¢
- **ç²¾åº¦é©—è­‰æ”¯æ´**ï¼šä¸»è¦ç”¨æ–¼é©—è­‰æª¢æ¸¬åˆ°çš„è§’é»èˆ‡é æœŸä½ç½®çš„åå·®
- **ç°¡æ½”å¯¦ç¾**ï¼šæä¾›ç°¡å–®æ˜“ç”¨çš„è·é›¢è¨ˆç®—å·¥å…·æ–¹æ³•

---

## ğŸ“Š **ç¨‹å¼æ•´é«”æµç¨‹ç¸½çµ**

1. **åˆå§‹åŒ–** â†’ å•Ÿå‹•ä»»å‹™ï¼Œç§»å‹•åˆ°è§€å¯Ÿä½ç½®
2. **å½±åƒç²å–** â†’ å¾å°èˆªç›¸æ©Ÿç²å–å½±åƒ
3. **æ¨™è¨˜æª¢æ¸¬** â†’ ä½¿ç”¨ArUcoæª¢æ¸¬æ¨™è¨˜
4. **å§¿æ…‹ä¼°è¨ˆ** â†’ è¨ˆç®—æ¨™è¨˜çš„3Dä½ç½®å’Œæ–¹å‘
5. **ç²¾åº¦é©—è­‰** â†’ æª¢æŸ¥æª¢æ¸¬ç²¾åº¦
6. **å½±åƒè£å‰ª** â†’ ç²¾ç¢ºæå–æ¨™è¨˜å‘¨åœå€åŸŸ
7. **è³‡æ–™è™•ç†** â†’ ç‚ºå¾ŒçºŒç‰©å“è­˜åˆ¥æº–å‚™æ•¸æ“š



&nbsp;

&nbsp;





# ğŸ“¦ **ç¨‹å¼é€è¡Œè§£æ**

```java
package jp.jaxa.iss.kibo.rpc.sampleapk;
```
**ç¬¬1è¡Œï¼š** å®šç¾©ç¨‹å¼åŒ…å

## **åŸºç¤åŒ¯å…¥**
```java
import jp.jaxa.iss.kibo.rpc.api.KiboRpcService;
import gov.nasa.arc.astrobee.types.Point;
import gov.nasa.arc.astrobee.types.Quaternion;
```
**ç¬¬3-5è¡Œï¼š** åŒ¯å…¥Astrobeeæ©Ÿå™¨äººæ§åˆ¶API

```java
import android.util.Log;
```
**ç¬¬10è¡Œï¼š** Androidæ—¥èªŒåŠŸèƒ½

```java
import java.util.List;
import java.util.ArrayList;
```
**ç¬¬12-13è¡Œï¼š** Javaé›†åˆé¡åˆ¥ï¼Œç”¨æ–¼å„²å­˜æª¢æ¸¬åˆ°çš„æ¨™è¨˜

## **OpenCVé›»è…¦è¦–è¦ºå‡½å¼åº«**
```java
import org.opencv.aruco.Dictionary;
import org.opencv.aruco.Aruco;
import org.opencv.core.*;
```
**ç¬¬16-18è¡Œï¼š** 
- `Dictionary` - ArUcoæ¨™è¨˜å­—å…¸
- `Aruco` - ArUcoæ¨™è¨˜æª¢æ¸¬åŠŸèƒ½
- `core.*` - OpenCVæ ¸å¿ƒåŠŸèƒ½ï¼ˆMat, Point, Sizeç­‰ï¼‰

```java
import org.opencv.imgproc.Imgproc;
```
**ç¬¬26è¡Œï¼š** å½±åƒè™•ç†åŠŸèƒ½ï¼ˆé¡è‰²è½‰æ›ã€é€è¦–è®Šæ›ç­‰ï¼‰

```java
import org.opencv.calib3d.Calib3d;
import gov.nasa.arc.astrobee.Result;
```
**ç¬¬29-30è¡Œï¼š** 
- `Calib3d` - ç›¸æ©Ÿæ¨™å®šå’Œ3Då¹¾ä½•é‹ç®—
- `Result` - APIå‘¼å«çµæœ

## ğŸš€ **ä¸»è¦ä»»å‹™åŸ·è¡Œï¼ˆrunPlan1æ–¹æ³•ï¼‰**

### **ä»»å‹™åˆå§‹åŒ–**
```java
Log.i(TAG, "Start mission");
api.startMission();
```
**ç¬¬44-46è¡Œï¼š** è¨˜éŒ„æ—¥èªŒä¸¦å•Ÿå‹•ä»»å‹™

### **æ©Ÿå™¨äººå®šä½**
```java
Point point = new Point(10.9d, -9.92284d, 5.195d);
Quaternion quaternion = new Quaternion(0f, 0f, -0.707f, 0.707f);
api.moveTo(point, quaternion, false);
```
**ç¬¬49-51è¡Œï¼š** ç§»å‹•åˆ°åˆå§‹è§€å¯Ÿä½ç½®

### **å½±åƒç²å–**
```java
Mat image = api.getMatNavCam();
api.saveMatImage(image, "test.png");
```
**ç¬¬54-56è¡Œï¼š** ç²å–ç›¸æ©Ÿå½±åƒä¸¦å„²å­˜

## ğŸ¯ **ArUcoæ¨™è¨˜æª¢æ¸¬æ ¸å¿ƒé‚è¼¯**

### **å»ºç«‹ArUcoå­—å…¸**
```java
Dictionary dictionary = Aruco.getPredefinedDictionary(Aruco.DICT_5X5_250);
```
**ç¬¬67è¡Œï¼š** 
- å»ºç«‹5x5å¤§å°çš„ArUcoæ¨™è¨˜å­—å…¸
- åŒ…å«250å€‹ä¸åŒçš„æ¨™è¨˜åœ–æ¡ˆ
- ç”¨æ–¼è­˜åˆ¥å’Œè¿½è¹¤æ¨™è¨˜

## **æª¢æ¸¬æ¨™è¨˜**
```java
List<Mat> corners = new ArrayList<>();
Mat ids = new Mat();
Aruco.detectMarkers(image, dictionary, corners, ids);
```
**ç¬¬73-75è¡Œï¼š** 
- `corners` - å„²å­˜æª¢æ¸¬åˆ°çš„æ¨™è¨˜è§’é»åº§æ¨™
- `ids` - å„²å­˜æ¨™è¨˜çš„IDç·¨è™Ÿ
- `detectMarkers` - åœ¨å½±åƒä¸­æª¢æ¸¬ArUcoæ¨™è¨˜

## **ç›¸æ©Ÿåƒæ•¸è¨­å®š**
```java
if (corners.size() > 0) {
    double[][] intrinsics = api.getNavCamIntrinsics();
    Mat cameraMatrix = new Mat(3, 3, CvType.CV_64F);
    Mat distCoeffs = new Mat(1, 5, CvType.CV_64F);
```
**ç¬¬77-80è¡Œï¼š** 
- æª¢æŸ¥æ˜¯å¦æª¢æ¸¬åˆ°æ¨™è¨˜
- ç²å–ç›¸æ©Ÿå…§åƒæ•¸ï¼ˆç„¦è·ã€ä¸»é»ã€ç•¸è®Šä¿‚æ•¸ï¼‰
- å»ºç«‹ç›¸æ©ŸçŸ©é™£å’Œç•¸è®Šä¿‚æ•¸çŸ©é™£

```java
cameraMatrix.put(0, 0, intrinsics[0]);
distCoeffs.put(0, 0, intrinsics[1]);
distCoeffs.convertTo(distCoeffs, CvType.CV_64F);
```
**ç¬¬82-84è¡Œï¼š** 
- å¡«å…¥ç›¸æ©Ÿå…§åƒæ•¸
- è½‰æ›ç‚º64ä½å…ƒæµ®é»æ•¸æ ¼å¼

## **å§¿æ…‹ä¼°è¨ˆ**
```java
Mat rvecs = new Mat();
Mat tvecs = new Mat();
float markerLength = 0.05f; // 5cm markers
Aruco.estimatePoseSingleMarkers(corners, markerLength, cameraMatrix, distCoeffs, rvecs, tvecs);
```
**ç¬¬87-91è¡Œï¼š** 
- `rvecs` - æ—‹è½‰å‘é‡ï¼ˆæ¨™è¨˜æ–¹å‘ï¼‰
- `tvecs` - å¹³ç§»å‘é‡ï¼ˆæ¨™è¨˜ä½ç½®ï¼‰
- `markerLength` - å¯¦éš›æ¨™è¨˜å¤§å°ï¼ˆ5å…¬åˆ†ï¼‰
- ä¼°è¨ˆæ¯å€‹æ¨™è¨˜çš„3Då§¿æ…‹

### **å½±åƒè™•ç†èˆ‡å¯è¦–åŒ–**
```java
Mat imageWithFrame = image.clone();
Mat imagewithcroparea = image.clone();
Aruco.drawDetectedMarkers(imageWithFrame, corners, ids);
Log.i(TAG, "Detected " + corners.size() + " markers.");
```
**ç¬¬94-98è¡Œï¼š** 
- è¤‡è£½åŸå§‹å½±åƒ
- åœ¨å½±åƒä¸Šç¹ªè£½æª¢æ¸¬åˆ°çš„æ¨™è¨˜
- è¨˜éŒ„æª¢æ¸¬åˆ°çš„æ¨™è¨˜æ•¸é‡

## ğŸ”„ **æ¨™è¨˜è™•ç†è¿´åœˆ**

```java
for (int i = 0; i < corners.size(); i++) {
    Mat currentCorners = corners.get(i);
    Mat UndistortImg = new Mat();
```
**ç¬¬101-105è¡Œï¼š** éæ­·æ¯å€‹æª¢æ¸¬åˆ°çš„æ¨™è¨˜

### **å§¿æ…‹å‘é‡è™•ç†**
```java
if (rvecs.rows() > 0 && tvecs.rows() > 0) {
    Mat rvec = new Mat(3, 1, CvType.CV_64F);
    Mat tvec = new Mat(3, 1, CvType.CV_64F);
    
    rvecs.row(i).copyTo(rvec);
    tvecs.row(i).copyTo(tvec);
```
**ç¬¬107-112è¡Œï¼š** 
- æª¢æŸ¥å§¿æ…‹æ•¸æ“šæ˜¯å¦æœ‰æ•ˆ
- æå–ç•¶å‰æ¨™è¨˜çš„æ—‹è½‰å’Œå¹³ç§»å‘é‡

### **åº§æ¨™è»¸ç¹ªè£½**
```java
Imgproc.cvtColor(imageWithFrame, imageWithFrame, Imgproc.COLOR_GRAY2RGB);
Aruco.drawAxis(imageWithFrame, cameraMatrix, distCoeffs, rvec, tvec, 0.1f);
```
**ç¬¬114-116è¡Œï¼š** 
- è½‰æ›å½±åƒç‚ºRGBæ ¼å¼
- ç¹ªè£½3Dåº§æ¨™è»¸ï¼ˆZ=ç´…, Y=ç¶ , X=è—ï¼‰

### **ç²¾å¯†è£å‰ªè™•ç†**
```java
MatOfPoint2f cornerPoints = new MatOfPoint2f(currentCorners);
checkCornerAndCropRegion(imagewithcroparea, cameraMatrix, distCoeffs, rvec, tvec, cornerPoints);
api.saveMatImage(imagewithcroparea, "marker_" + i + "_crop_area.png");
```
**ç¬¬118-121è¡Œï¼š** 
- è½‰æ›è§’é»æ ¼å¼
- å‘¼å«ç²¾å¯†è£å‰ªæ–¹æ³•
- å„²å­˜è£å‰ªå€åŸŸå½±åƒ

## ğŸ”§ **è¼”åŠ©æ–¹æ³•è©³ç´°è§£æ**

### **checkCornerAndCropRegionæ–¹æ³•**

```java
private void checkCornerAndCropRegion(Mat image, Mat cameraMatrix, Mat distCoeffs, 
                                    Mat rvec, Mat tvec, MatOfPoint2f corners) {
```
**ç¬¬194è¡Œï¼š** æª¢æŸ¥è§’é»ä½ç½®ä¸¦è£å‰ªå€åŸŸ

#### **3Dåˆ°2DæŠ•å½±é©—è­‰**
```java
org.opencv.core.Point3[] expectedPoint3D = {new org.opencv.core.Point3(-0.025, 0.025, 0)};
MatOfPoint3f expectedPointMat = new MatOfPoint3f(expectedPoint3D);
MatOfPoint2f projectedExpected = new MatOfPoint2f();
```
**ç¬¬201-203è¡Œï¼š** 
- å®šç¾©é æœŸçš„3Dåº§æ¨™é»ï¼ˆ-2.5cm, 2.5cm, 0ï¼‰
- æº–å‚™æŠ•å½±è¨ˆç®—

```java
Calib3d.projectPoints(expectedPointMat, rvec, tvec, cameraMatrix, distCoeffsDouble, projectedExpected);
```
**ç¬¬211è¡Œï¼š** å°‡3Dé»æŠ•å½±åˆ°2Då½±åƒåº§æ¨™

#### **ç²¾åº¦é©—è­‰**
```java
double distance = getdistance(expectedCorner, actualCorner);
if (distance > 10.0) {
    Log.i(TAG, String.format("Corner[0] not at expected position..."));
} else {
    Log.i(TAG, "Corner[0] is close to expected position (-2.5, 2.5, 0)");
}
```
**ç¬¬218-225è¡Œï¼š** 
- è¨ˆç®—é æœŸä½ç½®èˆ‡å¯¦éš›ä½ç½®çš„è·é›¢
- å¦‚æœèª¤å·®è¶…é10åƒç´ å‰‡è¨˜éŒ„è­¦å‘Š

#### **è£å‰ªå€åŸŸå®šç¾©**
```java
org.opencv.core.Point3[] cropCorners3D = {
    new org.opencv.core.Point3(-0.0325, 0.0375, 0),    // Top-left
    new org.opencv.core.Point3(-0.2325, 0.0375, 0),   // Top-right  
    new org.opencv.core.Point3(-0.2325, -0.1125, 0), // Bottom-right
    new org.opencv.core.Point3(-0.0325, -0.1125, 0)   // Bottom-left
};
```
**ç¬¬234-239è¡Œï¼š** å®šç¾©è£å‰ªå€åŸŸçš„å››å€‹3Dè§’é»ï¼ˆå–®ä½ï¼šå…¬å°ºï¼‰

### **cropAndSaveRegionæ–¹æ³•**

```java
org.opencv.core.Point[] dstPoints = {
    new org.opencv.core.Point(0, 0),       // Top-left
    new org.opencv.core.Point(639, 0),     // Top-right
    new org.opencv.core.Point(639, 479),   // Bottom-right
    new org.opencv.core.Point(0, 479)      // Bottom-left
};
```
**ç¬¬260-265è¡Œï¼š** å®šç¾©ç›®æ¨™çŸ©å½¢ï¼ˆ640x480åƒç´ ï¼‰

```java
Mat perspectiveMatrix = Imgproc.getPerspectiveTransform(srcPointsMat, dstPointsMat);
Imgproc.warpPerspective(image, croppedImage, perspectiveMatrix, new Size(640, 480));
```
**ç¬¬272-276è¡Œï¼š** 
- è¨ˆç®—é€è¦–è®Šæ›çŸ©é™£
- åŸ·è¡Œé€è¦–è®Šæ›ï¼ŒçŸ¯æ­£å‚¾æ–œçš„å½±åƒå€åŸŸ

### **cropMarkerRegionæ–¹æ³•**

```java
float[] cornerData = new float[(int)(markerCorners.total() * markerCorners.channels())];
markerCorners.get(0, 0, cornerData);
```
**ç¬¬295-296è¡Œï¼š** æå–æ¨™è¨˜è§’é»æ•¸æ“š

```java
for (int i = 0; i < cornerData.length; i += 2) {
    float x = cornerData[i];
    float y = cornerData[i + 1];
    
    minX = Math.min(minX, x);
    maxX = Math.max(maxX, x);
    minY = Math.min(minY, y);
    maxY = Math.max(maxY, y);
}
```
**ç¬¬301-309è¡Œï¼š** æ‰¾å‡ºåŒ…åœæ¨™è¨˜çš„æœ€å°çŸ©å½¢

```java
float padding = Math.max(maxX - minX, maxY - minY) * 0.2f;
```
**ç¬¬312è¡Œï¼š** æ·»åŠ 20%çš„é‚Šè·

### **sureMoveToPointæ–¹æ³•**

```java
private Result sureMoveToPoint(Point point, Quaternion quaternion, boolean printRobotPosition, int maxRetries) {
    Result result = api.moveTo(point, quaternion, printRobotPosition);
    
    int retryCount = 0;
    while (!result.hasSucceeded() && retryCount < maxRetries) {
        result = api.moveTo(point, quaternion, true);
        retryCount++;
    }
    return result;
}
```
**ç¬¬365-375è¡Œï¼š** 
- å¯é çš„ç§»å‹•æ–¹æ³•
- å¦‚æœç§»å‹•å¤±æ•—æœƒè‡ªå‹•é‡è©¦
- æœ€å¤šé‡è©¦maxRetriesæ¬¡

## ğŸ“Š **ç¨‹å¼æ•´é«”æµç¨‹ç¸½çµ**

1. **åˆå§‹åŒ–** â†’ å•Ÿå‹•ä»»å‹™ï¼Œç§»å‹•åˆ°è§€å¯Ÿä½ç½®
2. **å½±åƒç²å–** â†’ å¾å°èˆªç›¸æ©Ÿç²å–å½±åƒ
3. **æ¨™è¨˜æª¢æ¸¬** â†’ ä½¿ç”¨ArUcoæª¢æ¸¬æ¨™è¨˜
4. **å§¿æ…‹ä¼°è¨ˆ** â†’ è¨ˆç®—æ¨™è¨˜çš„3Dä½ç½®å’Œæ–¹å‘
5. **ç²¾åº¦é©—è­‰** â†’ æª¢æŸ¥æª¢æ¸¬ç²¾åº¦
6. **å½±åƒè£å‰ª** â†’ ç²¾ç¢ºæå–æ¨™è¨˜å‘¨åœå€åŸŸ
7. **è³‡æ–™è™•ç†** â†’ ç‚ºå¾ŒçºŒç‰©å“è­˜åˆ¥æº–å‚™æ•¸æ“š
